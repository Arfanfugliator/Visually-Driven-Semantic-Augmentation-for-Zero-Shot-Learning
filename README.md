# Visually-Driven-Semantic-Augmentation-for-Zero-Shot-Learning

We tackle the zero-shot learning (ZSL) classification problem and analyse one of its key ingredients, the semantic embedding. Despite their fundamental role, semantic embeddings are not learnt from the visual data to be classified, but, instead, they either come from manual annotation (attributes) or from a linguistic text corpus (distributed word embeddings, DWEs). 

Hence, there is no guarantee that visual and semantic information could fit well, and as to bridge this gap, we propose to augment the semantic information of attributes/DWEs with semantic representations directly extracted from visual data by means of soft labels. 

When combined in a novel ZSL paradigm based on latent attributes, our approach achieves favourable performances on three public benchmark datasets.

## Parameters Configurations

We provide the parameters configuration that we used in our BMVC 2018 paper for the results therein published

### Binary attributes
<table style="width:100%">
  <tr>
    <th>Dataset</th>
    <th> </th> 
    <th>Age</th>
  </tr>
  <tr>
    <td>Jill</td>
    <td>Smith</td> 
    <td>50</td>
  </tr>
  <tr>
    <td>Eve</td>
    <td>Jackson</td> 
    <td>94</td>
  </tr>
</table>

### Distributed word embeddings
<table style="width:100%">
  <tr>
    <th>Dataset</th>
    <th> </th> 
    <th>Age</th>
  </tr>
  <tr>
    <td>Jill</td>
    <td>Smith</td> 
    <td>50</td>
  </tr>
  <tr>
    <td>Eve</td>
    <td>Jackson</td> 
    <td>94</td>
  </tr>
</table>

### Combination of the two
<table style="width:100%">
  <tr>
    <th>Dataset</th>
    <th> </th> 
    <th>Age</th>
  </tr>
  <tr>
    <td>Jill</td>
    <td>Smith</td> 
    <td>50</td>
  </tr>
  <tr>
    <td>Eve</td>
    <td>Jackson</td> 
    <td>94</td>
  </tr>
</table>


#

<img src="https://vignette.wikia.nocookie.net/breakingbad/images/0/08/Work-in-progress-1024x603.png/revision/latest?cb=20170515215858" width=20% height=20%> ... code will be available soon
